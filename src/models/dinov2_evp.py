"""
DINOv2 with EVP (Environment-aware Visual Prompt Tuning)
æ ¸å¿ƒåˆ›æ–°: æ ¹æ®ç¯å¢ƒæ•°æ®åŠ¨æ€ç”Ÿæˆè§†è§‰æç¤º

V3: 
- ä½ç§©åˆ†è§£å¤§å¹…å‡å°‘å‚æ•°é‡
- åªåœ¨æœ€åNå±‚ä½¿ç”¨EVPï¼ˆå‡å°‘å¯¹æ—©æœŸå±‚å¹²æ‰°ï¼‰
- æ›´å¼ºçš„é—¨æ§æœºåˆ¶ï¼ˆåˆå§‹gateæ¥è¿‘0ï¼‰
"""

import torch
import torch.nn as nn
from typing import Optional, List, Tuple, Dict

from src.models.dinov2_adapter_prompt import Dinov2AdapterPrompt
from src.models.env_aware_prompt import EnvironmentPromptGenerator


class Dinov2EVP(nn.Module):
    """
    å¸¦EVPçš„DINOv2æ¨¡å‹
    åœ¨åŸæœ‰Dinov2AdapterPromptåŸºç¡€ä¸Šï¼Œå°†é™æ€Promptæ›¿æ¢ä¸ºç¯å¢ƒæ„ŸçŸ¥çš„åŠ¨æ€Prompt
    
    V3: 
    - ä½ç§©åˆ†è§£ï¼ŒEVPæ¨¡å—ä»…å¢åŠ ~0.9Må‚æ•°ï¼ˆåªæœ‰4å±‚ï¼‰
    - åªåœ¨æœ€å4å±‚ä½¿ç”¨EVPï¼Œå‡å°‘å¯¹æ—©æœŸç‰¹å¾çš„å¹²æ‰°
    - åˆå§‹gateâ‰ˆ0.05ï¼Œè®©æ¨¡å‹ä»baselineå¼€å§‹é€æ¸å­¦ä¹ EVPè´¡çŒ®
    """
    
    def __init__(
        self,
        base_model: Dinov2AdapterPrompt,
        env_dim: int = 27,
        use_evp: bool = True,
        evp_hidden_dim: int = 256,
        evp_dropout: float = 0.1,
        evp_rank: int = 16,
        freeze_base: bool = False,
        evp_layers: Optional[List[int]] = None,  # æ–°å¢ï¼šæŒ‡å®šEVPå±‚
        evp_gate_init: float = -3.0  # æ–°å¢ï¼šgateåˆå§‹å€¼ (sigmoid(-3)â‰ˆ0.047)
    ):
        super().__init__()
        
        self.base_model = base_model
        self.use_evp = use_evp
        self.env_dim = env_dim
        
        # è·å–åŸºç¡€æ¨¡å‹å‚æ•°
        self.embed_dim = base_model.embed_dim
        self.prompt_len = base_model.prompt_len
        self.num_layers = len(base_model.dino.blocks)
        
        # é»˜è®¤åªåœ¨æœ€å4å±‚ä½¿ç”¨EVP
        if evp_layers is None:
            self.evp_layers = list(range(self.num_layers - 4, self.num_layers))
        else:
            self.evp_layers = evp_layers
        
        self.evp_layers_set = set(self.evp_layers)
        
        if use_evp:
            # åˆ›å»ºè½»é‡çº§EVPç”Ÿæˆå™¨ (V3)
            self.evp_generator = EnvironmentPromptGenerator(
                env_dim=env_dim,
                prompt_len=self.prompt_len,
                embed_dim=self.embed_dim,
                hidden_dim=evp_hidden_dim,
                num_layers=self.num_layers,
                use_layer_specific=True,
                use_residual=True,
                use_gating=True,
                dropout=evp_dropout,
                rank=evp_rank,
                evp_layers=self.evp_layers,  # åªåœ¨æŒ‡å®šå±‚ä½¿ç”¨EVP
                gate_init_value=evp_gate_init  # åˆå§‹gateæ¥è¿‘0
            )
            print(f"âœ¨ EVP V3 enabled:")
            print(f"   env_dim={env_dim}, prompt_len={self.prompt_len}, rank={evp_rank}")
            print(f"   evp_layers={self.evp_layers} (only last {len(self.evp_layers)} layers)")
            print(f"   gate_init={evp_gate_init} (sigmoid={torch.sigmoid(torch.tensor(evp_gate_init)).item():.4f})")
        
        if freeze_base:
            for param in self.base_model.parameters():
                param.requires_grad = False
            print("ğŸ”’ Base model frozen, only training EVP")
        
        self._print_params()
    
    def _print_params(self):
        total = sum(p.numel() for p in self.parameters())
        trainable = sum(p.numel() for p in self.parameters() if p.requires_grad)
        
        # åˆ†åˆ«ç»Ÿè®¡
        base_params = sum(p.numel() for p in self.base_model.parameters())
        evp_params = sum(p.numel() for p in self.evp_generator.parameters()) if self.use_evp else 0
        
        print(f"ğŸ“Š EVP V3 Model Statistics:")
        print(f"   Base model: {base_params:,} ({base_params/1e6:.2f}M)")
        print(f"   EVP module: {evp_params:,} ({evp_params/1e6:.2f}M)")
        print(f"   Total: {total:,} ({total/1e6:.2f}M)")
        print(f"   Trainable: {trainable:,} ({100*trainable/total:.2f}%)")
    
    def _is_evp_layer(self, layer_idx: int) -> bool:
        """æ£€æŸ¥è¯¥å±‚æ˜¯å¦ä½¿ç”¨EVP"""
        return layer_idx in self.evp_layers_set
    
    def forward(
        self, 
        img: torch.Tensor, 
        env: Optional[torch.Tensor] = None
    ) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        """
        batch_size = img.size(0)
        
        # Channel adapter
        if self.base_model.channel_adapter is not None:
            x = self.base_model.channel_adapter(img)
        elif self.base_model.in_channels > 3:
            x = img[:, :3, :, :]
        else:
            x = img
        
        # Patch embedding
        x = self.base_model.dino.patch_embed(x)
        
        # Add CLS token
        if self.base_model.dino.cls_token is not None:
            cls_token = self.base_model.dino.cls_token.expand(batch_size, -1, -1)
            x = torch.cat([cls_token, x], dim=1)
        
        # Position embedding + dropout
        x = x + self.base_model.dino.pos_embed
        x = self.base_model.dino.pos_drop(x)
        
        # å¤„ç†ç¯å¢ƒç‰¹å¾
        if env is not None:
            env = torch.nan_to_num(env, nan=0.0)
        
        # é€šè¿‡æ‰€æœ‰blocks
        for layer_idx, block in enumerate(self.base_model.dino.blocks):
            # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨EVP
            use_evp_this_layer = (
                self.use_evp and 
                env is not None and 
                self._is_evp_layer(layer_idx)
            )
            
            if use_evp_this_layer:
                # EVPå±‚ï¼šç”Ÿæˆç¯å¢ƒæ„ŸçŸ¥çš„åŠ¨æ€prompts
                dynamic_prompts, _ = self.evp_generator(env, layer_idx=layer_idx)
                prompts_to_use = dynamic_prompts
            else:
                # éEVPå±‚ï¼šä½¿ç”¨åŸæœ‰adapted_encoderä¸­çš„é™æ€prompts
                if self.base_model.adapted_encoder.use_layer_specific_prompts:
                    prompts_to_use = self.base_model.adapted_encoder.prompts[layer_idx](batch_size)
                else:
                    prompts_to_use = self.base_model.adapted_encoder.shared_prompts(batch_size)
            
            # æ·»åŠ promptsåˆ°åºåˆ—
            x_with_prompts = torch.cat([x, prompts_to_use], dim=1)
            
            # é€šè¿‡block
            x_with_prompts = block(x_with_prompts)
            
            # ç§»é™¤prompts
            x = x_with_prompts[:, :-self.prompt_len, :]
        
        # Final norm
        x = self.base_model.dino.norm(x)
        
        # è·å–CLS tokenç‰¹å¾
        cls_features = x[:, 0]
        
        # ç¯å¢ƒç‰¹å¾èåˆ (å¤ç”¨base_modelçš„fusion)
        if self.base_model.use_env and env is not None:
            try:
                from src.models.adaptive_fusion import AdaptiveEnvironmentalFusion
                ADAPTIVE_FUSION_AVAILABLE = True
            except ImportError:
                ADAPTIVE_FUSION_AVAILABLE = False
            
            if self.base_model.fusion_type == "adaptive_attention" and ADAPTIVE_FUSION_AVAILABLE:
                fused_feat = self.base_model.fusion(cls_features, env)
            elif self.base_model.fusion_type in ["cross_attention", "adaptive_attention"]:
                env_feat = self.base_model.env_encoder(env)
                fused_feat = self.base_model.fusion(cls_features, env_feat)
            elif self.base_model.fusion_type == "concat":
                env_feat = self.base_model.env_encoder(env)
                fused_feat = torch.cat([cls_features, env_feat], dim=1)
            else:
                fused_feat = cls_features
        else:
            fused_feat = cls_features
        
        # åˆ†ç±»
        logits = self.base_model.classifier(fused_feat)
        
        return logits
    
    def get_evp_gate_values(self, env: torch.Tensor) -> Dict[int, torch.Tensor]:
        """è·å–æ‰€æœ‰EVPå±‚çš„é—¨æ§å€¼"""
        if not self.use_evp:
            return {}
        
        _, all_gates = self.evp_generator.get_all_prompts(env)
        return all_gates


def create_dinov2_evp_model(config) -> Dinov2EVP:
    """
    åˆ›å»ºDINOv2 EVPæ¨¡å‹çš„å·¥å‚å‡½æ•°
    """
    module_cfg = config.experiment.module
    data_cfg = config.data
    
    # è·å–ç¯å¢ƒç‰¹å¾ç»´åº¦
    env_dim = sum(data_cfg.env_var_sizes) if hasattr(data_cfg, 'env_var_sizes') else 27
    num_classes = data_cfg.total_species
    
    # åˆ›å»ºåŸºç¡€æ¨¡å‹
    base_model = Dinov2AdapterPrompt(
        num_classes=num_classes,
        dino_model_name=getattr(module_cfg, 'dino_model', 'vit_base_patch14_dinov2.lvd142m'),
        pretrained_path=getattr(module_cfg, 'pretrained_path', 'checkpoints/dinov2_vitb14_pretrain.pth'),
        prompt_len=getattr(module_cfg, 'prompt_len', 40),
        bottleneck_dim=getattr(module_cfg, 'bottleneck_dim', 96),
        env_input_dim=env_dim,
        env_hidden_dim=getattr(module_cfg, 'env_hidden_dim', 2048),
        env_num_layers=getattr(module_cfg, 'env_num_layers', 6),
        use_env=True,
        fusion_type=getattr(module_cfg, 'fusion_type', 'adaptive_attention'),
        use_channel_adapter=getattr(module_cfg, 'use_channel_adapter', True),
        in_channels=getattr(module_cfg, 'in_channels', 4),
        channel_adapter_type=getattr(module_cfg, 'channel_adapter_type', 'learned'),
        freeze_backbone=getattr(module_cfg, 'freeze_backbone', True),
        unfreeze_last_n_blocks=getattr(module_cfg, 'unfreeze_last_n_blocks', 4),
        use_dropkey=getattr(module_cfg, 'use_dropkey', True),
        dropkey_rate=getattr(module_cfg, 'dropkey_rate', 0.15),
        hidden_dims=getattr(module_cfg, 'hidden_dims', [2048, 1024]),
        dropout=getattr(module_cfg, 'dropout', 0.15),
    )
    
    # è§£æEVPå±‚é…ç½®
    evp_layers_config = getattr(module_cfg, 'evp_layers', None)
    if evp_layers_config is not None:
        evp_layers = list(evp_layers_config)
    else:
        evp_layers = None  # ä½¿ç”¨é»˜è®¤ï¼ˆæœ€å4å±‚ï¼‰
    
    # åˆ›å»ºEVPåŒ…è£…å™¨ (V3)
    evp_model = Dinov2EVP(
        base_model=base_model,
        env_dim=env_dim,
        use_evp=getattr(module_cfg, 'use_evp', True),
        evp_hidden_dim=getattr(module_cfg, 'evp_hidden_dim', 256),
        evp_dropout=getattr(module_cfg, 'evp_dropout', 0.1),
        evp_rank=getattr(module_cfg, 'evp_rank', 16),
        freeze_base=getattr(module_cfg, 'freeze_base_for_evp', False),
        evp_layers=evp_layers,
        evp_gate_init=getattr(module_cfg, 'evp_gate_init', -3.0),  # æ–°å¢é…ç½®
    )
    
    print("âœ… Created DINOv2 EVP model (V3 - Last 4 Layers + Strong Gate)")
    
    return evp_model
