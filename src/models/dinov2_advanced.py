"""
Enhanced DINOv2 with Advanced Techniques
åŒ…å«ä»¥ä¸‹æ”¹è¿›:
1. DropKey Attention - æ³¨æ„åŠ›æ­£åˆ™åŒ–
2. Multi-Scale Feature Aggregation - å¤šå°ºåº¦ç‰¹å¾èåˆ
3. Gated Cross-Attention Fusion - é—¨æ§å¤šæ¨¡æ€èåˆ
4. Enhanced Environment Encoder - å¢å¼ºç¯å¢ƒç¼–ç 
5. Self-Distillation - è‡ªè’¸é¦æ”¯æŒ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Optional, Tuple, List
import timm


class DropKeyAttention(nn.Module):
    """
    DropKey: åœ¨è®­ç»ƒæ—¶éšæœºä¸¢å¼ƒéƒ¨åˆ†key tokens
    ä½¿ç”¨monkey-patchingæ–¹å¼æ³¨å…¥ï¼Œä¿æŒé¢„è®­ç»ƒæƒé‡å…¼å®¹æ€§
    """
    
    def __init__(self, attn_module: nn.Module, drop_rate: float = 0.1):
        super().__init__()
        self.attn_module = attn_module
        self.drop_rate = drop_rate
        self._original_forward = None
        
    def inject_dropkey(self):
        """å°†dropkeyæ³¨å…¥åˆ°attentionæ¨¡å—"""
        if self._original_forward is None:
            self._original_forward = self.attn_module.forward
            
        def forward_with_dropkey(x):
            if self.training and self.drop_rate > 0:
                B, N, C = x.shape
                # éšæœºä¿ç•™çš„tokenæ•°é‡
                keep_tokens = int(N * (1 - self.drop_rate))
                if keep_tokens < N:
                    # éšæœºé€‰æ‹©è¦ä¿ç•™çš„indices
                    indices = torch.randperm(N, device=x.device)[:keep_tokens]
                    indices = indices.sort()[0]  # ä¿æŒé¡ºåº
                    x = x[:, indices, :]
            return self._original_forward(x)
        
        self.attn_module.forward = forward_with_dropkey


class MultiScaleAggregation(nn.Module):
    """
    å¤šå°ºåº¦ç‰¹å¾èšåˆæ¨¡å— (ç±»ä¼¼FPN)
    ä»DINOv2çš„å¤šä¸ªå±‚æå–ç‰¹å¾å¹¶èåˆ
    """
    
    def __init__(
        self,
        feature_dims: List[int],
        output_dim: int = 768,
        num_scales: int = 4
    ):
        super().__init__()
        self.num_scales = num_scales
        
        # ä¸ºæ¯ä¸ªå°ºåº¦åˆ›å»ºæŠ•å½±å±‚
        self.projections = nn.ModuleList([
            nn.Sequential(
                nn.Linear(dim, output_dim),
                nn.LayerNorm(output_dim),
                nn.GELU()
            ) for dim in feature_dims
        ])
        
        # èåˆå±‚
        self.fusion = nn.Sequential(
            nn.Linear(output_dim * num_scales, output_dim),
            nn.LayerNorm(output_dim),
            nn.GELU()
        )
        
    def forward(self, features: List[torch.Tensor]) -> torch.Tensor:
        """
        Args:
            features: List of [B, N, D] tensors from different layers
        Returns:
            fused_features: [B, D] tensor
        """
        # æŠ•å½±æ¯ä¸ªå°ºåº¦çš„ç‰¹å¾
        projected = []
        for i, feat in enumerate(features[:self.num_scales]):
            # æå–CLS token
            cls_token = feat[:, 0]  # [B, D]
            proj = self.projections[i](cls_token)  # [B, output_dim]
            projected.append(proj)
        
        # æ‹¼æ¥å¹¶èåˆ
        concat_features = torch.cat(projected, dim=1)  # [B, output_dim * num_scales]
        fused = self.fusion(concat_features)  # [B, output_dim]
        
        return fused


class GatedCrossAttentionFusion(nn.Module):
    """
    é—¨æ§äº¤å‰æ³¨æ„åŠ›èåˆ
    å­¦ä¹ å¦‚ä½•åŠ¨æ€èåˆå«æ˜Ÿå›¾åƒç‰¹å¾å’Œç¯å¢ƒç‰¹å¾
    """
    
    def __init__(
        self,
        sat_dim: int = 768,
        env_dim: int = 512,
        num_heads: int = 8,
        dropout: float = 0.1
    ):
        super().__init__()
        
        # äº¤å‰æ³¨æ„åŠ›
        self.cross_attn = nn.MultiheadAttention(
            embed_dim=sat_dim,
            num_heads=num_heads,
            dropout=dropout,
            batch_first=True
        )
        
        # ç¯å¢ƒç‰¹å¾æŠ•å½±åˆ°sat_dim
        self.env_proj = nn.Linear(env_dim, sat_dim)
        
        # é—¨æ§æœºåˆ¶
        self.gate = nn.Sequential(
            nn.Linear(sat_dim * 2, sat_dim),
            nn.Sigmoid()
        )
        
        self.norm1 = nn.LayerNorm(sat_dim)
        self.norm2 = nn.LayerNorm(sat_dim)
        
    def forward(
        self,
        sat_features: torch.Tensor,  # [B, sat_dim]
        env_features: torch.Tensor   # [B, env_dim]
    ) -> torch.Tensor:
        """
        Returns:
            fused_features: [B, sat_dim]
        """
        # æŠ•å½±ç¯å¢ƒç‰¹å¾
        env_proj = self.env_proj(env_features)  # [B, sat_dim]
        
        # æ·»åŠ åºåˆ—ç»´åº¦ç”¨äºattention
        sat_seq = sat_features.unsqueeze(1)  # [B, 1, sat_dim]
        env_seq = env_proj.unsqueeze(1)  # [B, 1, sat_dim]
        
        # äº¤å‰æ³¨æ„åŠ›: sat attend to env
        attn_out, _ = self.cross_attn(
            query=sat_seq,
            key=env_seq,
            value=env_seq
        )  # [B, 1, sat_dim]
        attn_out = attn_out.squeeze(1)  # [B, sat_dim]
        
        # æ®‹å·®è¿æ¥
        attn_out = self.norm1(sat_features + attn_out)
        
        # é—¨æ§èåˆ
        gate_input = torch.cat([sat_features, attn_out], dim=1)  # [B, sat_dim*2]
        gate_weights = self.gate(gate_input)  # [B, sat_dim]
        
        fused = gate_weights * attn_out + (1 - gate_weights) * sat_features
        fused = self.norm2(fused)
        
        return fused


class EnhancedEnvEncoder(nn.Module):
    """
    å¢å¼ºçš„ç¯å¢ƒç‰¹å¾ç¼–ç å™¨
    ä½¿ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶æ•æ‰ç¯å¢ƒå˜é‡ä¹‹é—´çš„å…³ç³»
    """
    
    def __init__(
        self,
        num_features: int = 27,
        hidden_dim: int = 512,
        num_heads: int = 4,
        num_layers: int = 2,
        dropout: float = 0.1
    ):
        super().__init__()
        
        # è¾“å…¥æŠ•å½±
        self.input_proj = nn.Linear(num_features, hidden_dim)
        
        # è‡ªæ³¨æ„åŠ›å±‚
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=hidden_dim,
            nhead=num_heads,
            dim_feedforward=hidden_dim * 4,
            dropout=dropout,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
        # è¾“å‡ºæŠ•å½±
        self.output_proj = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.GELU(),
            nn.Dropout(dropout)
        )
        
    def forward(self, env_features: torch.Tensor) -> torch.Tensor:
        """
        Args:
            env_features: [B, num_features]
        Returns:
            encoded: [B, hidden_dim]
        """
        # æ·»åŠ åºåˆ—ç»´åº¦
        x = self.input_proj(env_features).unsqueeze(1)  # [B, 1, hidden_dim]
        
        # è‡ªæ³¨æ„åŠ›
        x = self.transformer(x)  # [B, 1, hidden_dim]
        
        # è¾“å‡º
        x = x.squeeze(1)  # [B, hidden_dim]
        x = self.output_proj(x)
        
        return x


class EnhancedDinov2Multimodal(nn.Module):
    """
    å¢å¼ºç‰ˆDINOv2å¤šæ¨¡æ€æ¨¡å‹
    é›†æˆæ‰€æœ‰æ€§èƒ½æ”¹è¿›æŠ€æœ¯
    """
    
    def __init__(
        self,
        num_species: int,
        dinov2_name: str = "dinov2_vitb14",
        dinov2_pretrained: bool = True,
        proj_dim: int = 768,
        freeze_dinov2: bool = True,
        # Advanced features
        drop_key_rate: float = 0.1,
        use_multi_scale: bool = True,
        use_gated_fusion: bool = True,
        use_enhanced_env: bool = True,
        use_self_distill: bool = False,
        # Regularization
        drop_path_rate: float = 0.1,
        dropout: float = 0.2,
        # Environment
        num_env_features: int = 27,
        env_hidden_dim: int = 512,
        # Other
        device: str = "cuda"
    ):
        super().__init__()
        
        self.num_species = num_species
        self.proj_dim = proj_dim
        self.freeze_dinov2 = freeze_dinov2
        self.use_multi_scale = use_multi_scale
        self.use_gated_fusion = use_gated_fusion
        self.use_enhanced_env = use_enhanced_env
        self.use_self_distill = use_self_distill
        self.drop_key_rate = drop_key_rate
        
        # åŠ è½½DINOv2 backbone
        if dinov2_pretrained:
            # ä½¿ç”¨ torch.hub åŠ è½½ DINOv2
            self.dinov2 = torch.hub.load('facebookresearch/dinov2', dinov2_name)
        else:
            # å¦‚æœä¸éœ€è¦é¢„è®­ç»ƒæƒé‡ï¼Œä½¿ç”¨ timm
            try:
                self.dinov2 = timm.create_model(
                    dinov2_name,
                    pretrained=False,
                    num_classes=0
                )
            except:
                # åå¤‡æ–¹æ¡ˆï¼šä» hub åŠ è½½
                self.dinov2 = torch.hub.load('facebookresearch/dinov2', dinov2_name)
        
        # è·å–ç‰¹å¾ç»´åº¦
        if hasattr(self.dinov2, 'embed_dim'):
            backbone_dim = self.dinov2.embed_dim
        else:
            backbone_dim = 768  # default for vitb14
        
        # æ·»åŠ é€šé“è½¬æ¢å±‚ (4é€šé“RGBNIR -> 3é€šé“RGB)
        self.channel_adapter = nn.Conv2d(4, 3, kernel_size=1, bias=False)
        nn.init.xavier_uniform_(self.channel_adapter.weight)
        
        # å†»ç»“backbone
        if freeze_dinov2:
            for param in self.dinov2.parameters():
                param.requires_grad = False
        
        # DropKeyæ³¨å…¥ (å¦‚æœå¯ç”¨)
        if drop_key_rate > 0:
            self._inject_dropkey()
        
        # å¤šå°ºåº¦èšåˆ
        if use_multi_scale:
            # ä»ç¬¬3, 7, 11å±‚æå–ç‰¹å¾
            self.multi_scale_agg = MultiScaleAggregation(
                feature_dims=[backbone_dim] * 4,
                output_dim=proj_dim,
                num_scales=4
            )
        else:
            # ç®€å•æŠ•å½±
            self.sat_proj = nn.Sequential(
                nn.Linear(backbone_dim, proj_dim),
                nn.LayerNorm(proj_dim),
                nn.GELU()
            )
        
        # ç¯å¢ƒç¼–ç å™¨
        if use_enhanced_env:
            self.env_encoder = EnhancedEnvEncoder(
                num_features=num_env_features,
                hidden_dim=env_hidden_dim,
                num_heads=4,
                num_layers=2,
                dropout=dropout
            )
        else:
            self.env_encoder = nn.Sequential(
                nn.Linear(num_env_features, env_hidden_dim),
                nn.LayerNorm(env_hidden_dim),
                nn.GELU(),
                nn.Dropout(dropout)
            )
        
        # é—¨æ§èåˆ
        if use_gated_fusion:
            self.fusion = GatedCrossAttentionFusion(
                sat_dim=proj_dim,
                env_dim=env_hidden_dim,
                num_heads=8,
                dropout=dropout
            )
        else:
            # ç®€å•æ‹¼æ¥
            self.fusion = nn.Sequential(
                nn.Linear(proj_dim + env_hidden_dim, proj_dim),
                nn.LayerNorm(proj_dim),
                nn.GELU(),
                nn.Dropout(dropout)
            )
        
        # åˆ†ç±»å™¨
        self.classifier = nn.Sequential(
            nn.Dropout(dropout),
            nn.Linear(proj_dim, proj_dim // 2),
            nn.LayerNorm(proj_dim // 2),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(proj_dim // 2, num_species)
        )
        
        # è‡ªè’¸é¦åˆ†æ”¯ (å¦‚æœå¯ç”¨)
        if use_self_distill:
            self.distill_classifier = nn.Linear(proj_dim, num_species)
        
        print(f"âœ… Created Enhanced DINOv2:")
        print(f"   - Model: {dinov2_name}")
        print(f"   - DropKey: {drop_key_rate}")
        print(f"   - Multi-scale: {use_multi_scale}")
        print(f"   - Gated fusion: {use_gated_fusion}")
        print(f"   - Enhanced env: {use_enhanced_env}")
        print(f"   - Self-distill: {use_self_distill}")
        
    def _inject_dropkey(self):
        """
        ä¸º DINOv2 çš„ attention å±‚æ·»åŠ é¢å¤–çš„ dropout
        è¿™æ˜¯ä¸€ç§ç®€åŒ–çš„ DropKey å®ç°
        """
        if hasattr(self.dinov2, 'blocks'):
            for block in self.dinov2.blocks:
                if hasattr(block, 'attn') and hasattr(block.attn, 'attn_drop'):
                    # attn_drop æ˜¯ nn.Dropout å¯¹è±¡ï¼Œä¿®æ”¹å…¶ p å±æ€§
                    if isinstance(block.attn.attn_drop, nn.Dropout):
                        block.attn.attn_drop.p = max(block.attn.attn_drop.p, self.drop_key_rate)
                    
        print(f"   - Injected DropKey (dropout={self.drop_key_rate}) into attention layers")
    
    def forward(
        self,
        sat_images: torch.Tensor,
        env_features: torch.Tensor
    ) -> Dict[str, torch.Tensor]:
        """
        Args:
            sat_images: [B, 3, H, W]
            env_features: [B, num_env_features]
            
        Returns:
            dict with keys: 'logits', 'pred', 'logit_sum', 'features'
            (and 'distill_logits' if self.use_self_distill)
        """
        B = sat_images.size(0)
        
        # é€šé“è½¬æ¢: 4é€šé“(RGBNIR) -> 3é€šé“(RGB)
        if sat_images.size(1) == 4:
            sat_images = self.channel_adapter(sat_images)
        
        # æå–å«æ˜Ÿå›¾åƒç‰¹å¾ - å•å°ºåº¦
        # DINOv2 forward_features è¿”å›å­—å…¸ï¼Œéœ€è¦æå– x_norm_clstoken
        features_dict = self.dinov2.forward_features(sat_images)
        if isinstance(features_dict, dict):
            sat_features = features_dict['x_norm_clstoken']  # [B, D]
        else:
            # å¦‚æœä¸æ˜¯å­—å…¸ï¼Œå¯èƒ½æ˜¯å¼ é‡
            sat_features = features_dict[:, 0] if features_dict.dim() > 2 else features_dict
        sat_features = self.sat_proj(sat_features)  # [B, proj_dim]
        
        # ç¼–ç ç¯å¢ƒç‰¹å¾
        env_encoded = self.env_encoder(env_features)  # [B, env_hidden_dim]
        
        # èåˆ
        if self.use_gated_fusion:
            fused_features = self.fusion(sat_features, env_encoded)
        else:
            fused_features = self.fusion(torch.cat([sat_features, env_encoded], dim=1))
        
        # åˆ†ç±»
        logits = self.classifier(fused_features)  # [B, num_species]
        pred = torch.sigmoid(logits)
        
        outputs = {
            'logits': logits,
            'pred': pred,
            'logit_sum': logits,  # å…¼å®¹BCE loss
            'features': fused_features
        }
        
        # è‡ªè’¸é¦
        if self.use_self_distill and self.training:
            distill_logits = self.distill_classifier(fused_features.detach())
            outputs['distill_logits'] = distill_logits
        
        return outputs
    
    def is_backbone_frozen(self) -> bool:
        """æ£€æŸ¥backboneæ˜¯å¦è¢«å†»ç»“"""
        return not next(self.dinov2.parameters()).requires_grad
    
    def unfreeze_backbone(self):
        """è§£å†»backbone"""
        for param in self.dinov2.parameters():
            param.requires_grad = True
        self.freeze_dinov2 = False
        print("âœ… DINOv2 backbone unfrozen")
    
    def freeze_backbone(self):
        """å†»ç»“backbone"""
        for param in self.dinov2.parameters():
            param.requires_grad = False
        self.freeze_dinov2 = True
        print("ğŸ”’ DINOv2 backbone frozen")


if __name__ == "__main__":
    print("Testing Enhanced DINOv2...")
    
    model = EnhancedDinov2Multimodal(
        num_species=670,
        dinov2_name="dinov2_vits14",
        dinov2_pretrained=False,
        drop_key_rate=0.1,
        use_multi_scale=True,
        use_gated_fusion=True,
        use_enhanced_env=True,
        use_self_distill=True
    )
    
    sat = torch.randn(2, 3, 224, 224)
    env = torch.randn(2, 27)
    
    outputs = model(sat, env)
    print(f"âœ… Logits shape: {outputs['logits'].shape}")
    print(f"âœ… Pred shape: {outputs['pred'].shape}")
    if 'distill_logits' in outputs:
        print(f"âœ… Distill logits shape: {outputs['distill_logits'].shape}")
    
    total_params = sum(p.numel() for p in model.parameters())
    print(f"âœ… Total parameters: {total_params/1e6:.1f}M")
