#!/usr/bin/env python3
"""
å¤§è§„æ¨¡å¯è§£é‡Šæ€§åˆ†æè„šæœ¬ v2
- ä¿®å¤checkpointè·¯å¾„å’Œkeyåç§°
"""

import os
import sys
import json
import torch
import numpy as np
import pandas as pd
import rasterio
from tqdm import tqdm

sys.path.insert(0, '/sunyuxuan/satbird')

# ç¯å¢ƒå˜é‡åç§°
BIOCLIM_NAMES = [
    'BIO1: Annual Mean Temp', 'BIO2: Mean Diurnal Range', 'BIO3: Isothermality',
    'BIO4: Temp Seasonality', 'BIO5: Max Temp Warmest', 'BIO6: Min Temp Coldest',
    'BIO7: Temp Annual Range', 'BIO8: Mean Temp Wettest', 'BIO9: Mean Temp Driest',
    'BIO10: Mean Temp Warmest Q', 'BIO11: Mean Temp Coldest Q', 'BIO12: Annual Precip',
    'BIO13: Precip Wettest Month', 'BIO14: Precip Driest Month', 'BIO15: Precip Seasonality',
    'BIO16: Precip Wettest Q', 'BIO17: Precip Driest Q', 'BIO18: Precip Warmest Q',
    'BIO19: Precip Coldest Q'
]

PED_NAMES = [
    'PED1: Aspect', 'PED2: Organic Carbon', 'PED3: Slope', 'PED4: TPI',
    'PED5: Clay', 'PED6: Bulk Density', 'PED7: Cation Exchange', 'PED8: Elevation'
]


def load_sample(data_dir, hotspot_id):
    """åŠ è½½å•ä¸ªæ ·æœ¬"""
    env_path = os.path.join(data_dir, 'environmental', f'{hotspot_id}.npy')
    img_path = os.path.join(data_dir, 'images', f'{hotspot_id}.tif')
    
    if not os.path.exists(env_path) or not os.path.exists(img_path):
        return None
    
    env_data = np.load(env_path).astype(np.float32)
    
    with rasterio.open(img_path) as src:
        img = src.read().astype(np.float32)
    
    img = np.clip(img / 10000.0, 0, 1)
    
    if img.shape[1] != 224 or img.shape[2] != 224:
        from torchvision.transforms.functional import resize
        img = resize(torch.from_numpy(img), [224, 224]).numpy()
    
    return {'image': torch.from_numpy(img), 'env_data': torch.from_numpy(env_data)}


def build_model_from_checkpoint(ckpt_path, env_dim, device):
    """ä»checkpointæ„å»ºæ¨¡å‹"""
    from src.models.dinov2_adapter_prompt import Dinov2AdapterPrompt
    
    ckpt = torch.load(ckpt_path, map_location='cpu')
    state_dict = ckpt.get('state_dict', ckpt)
    
    # æå–å‚æ•°
    # æ‰¾åˆ°num_classes
    for k in state_dict:
        if 'classifier' in k and 'weight' in k:
            if state_dict[k].dim() == 2:
                num_classes = state_dict[k].shape[0]
                if num_classes > 100:  # ç¡®ä¿æ˜¯æœ€åä¸€å±‚
                    break
    
    # æ‰¾åˆ°env_hidden_dim
    for k in state_dict:
        if 'fusion.env_encoder.0.weight' in k or 'env_encoder.encoder.0.weight' in k:
            env_hidden_dim = state_dict[k].shape[0]
            break
    else:
        env_hidden_dim = 2048
    
    print(f"  num_classes={num_classes}, env_hidden_dim={env_hidden_dim}, env_dim={env_dim}")
    
    # åˆ›å»ºæ¨¡å‹
    model = Dinov2AdapterPrompt(
        num_classes=num_classes,
        pretrained=False,
        model_size='base',
        use_adapter=True,
        use_prompt=True,
        adapter_dim=64,
        prompt_len=4,
        env_input_dim=env_dim,
        env_hidden_dim=env_hidden_dim,
        use_env=True
    )
    
    # å¤„ç†state_dict key
    new_state_dict = {}
    for k, v in state_dict.items():
        new_k = k
        if k.startswith('model.'):
            new_k = k[6:]
        new_state_dict[new_k] = v
    
    msg = model.load_state_dict(new_state_dict, strict=False)
    print(f"  åŠ è½½: {len(msg.missing_keys)} missing, {len(msg.unexpected_keys)} unexpected")
    
    return model.to(device)


def extract_info(model, image, env_data, device):
    """æå–é—¨æ§å€¼å’Œç¯å¢ƒå˜é‡æ¢¯åº¦"""
    model.eval()
    
    if len(image.shape) == 3:
        image = image.unsqueeze(0)
    if len(env_data.shape) == 3:
        env_data = env_data.unsqueeze(0)
    
    image = image.to(device)
    env_data = env_data.to(device).requires_grad_(True)
    
    # å‰å‘ä¼ æ’­
    try:
        output = model(image, env_data)
    except Exception as e:
        # æŸäº›æ¨¡å‹å¯èƒ½éœ€è¦ä¸åŒçš„è°ƒç”¨æ–¹å¼
        output = model(image, env_features=env_data)
    
    # è®¡ç®—æ¢¯åº¦
    target = output.abs().sum()
    target.backward()
    
    env_grad = env_data.grad.detach()
    
    # ç¯å¢ƒå˜é‡é‡è¦æ€§ = |gradient| * |value|
    env_importance = (env_grad.abs() * env_data.detach().abs()).mean(dim=(2, 3)).cpu().numpy()[0]
    
    # æå–alpha
    alpha_val = None
    with torch.no_grad():
        if hasattr(model, 'channel_adapter') and model.channel_adapter is not None:
            x = model.channel_adapter(image)
        else:
            x = image
        
        visual_features = model.encoder(x)
        env_processed = model.env_encoder(env_data.detach())
        
        if hasattr(model, 'cross_modal_fusion') and model.cross_modal_fusion is not None:
            try:
                _, alpha = model.cross_modal_fusion(visual_features, env_processed, return_alpha=True)
                alpha_val = alpha.cpu().item()
            except:
                pass
    
    return {
        'alpha': alpha_val,
        'env_importance': env_importance
    }


def analyze_domain(name, data_dir, ckpt_path, max_samples=2000, device='cuda'):
    """åˆ†æå•ä¸ªåŸŸ"""
    print(f"\n{'='*70}")
    print(f"åˆ†æåŸŸ: {name}")
    print(f"{'='*70}")
    
    if not os.path.exists(ckpt_path):
        print(f"  Checkpointä¸å­˜åœ¨: {ckpt_path}")
        return None
    
    split_file = os.path.join(data_dir, 'test_split.csv')
    if not os.path.exists(split_file):
        print(f"  Splitæ–‡ä»¶ä¸å­˜åœ¨")
        return None
    
    # æ£€æµ‹ç¯å¢ƒç»´åº¦
    env_dim = 19 if 'kenya' in data_dir.lower() else 27
    
    # æ„å»ºæ¨¡å‹
    model = build_model_from_checkpoint(ckpt_path, env_dim, device)
    model.eval()
    
    # åŠ è½½æ•°æ®
    df = pd.read_csv(split_file)
    total_samples = len(df)
    hotspot_ids = df['hotspot_id'].tolist()[:max_samples]
    
    print(f"  åˆ†ææ ·æœ¬: {min(len(hotspot_ids), max_samples)}/{total_samples}")
    
    # åˆ†æ
    alphas = []
    all_importance = []
    
    for hid in tqdm(hotspot_ids, desc=f"åˆ†æ {name}"):
        sample = load_sample(data_dir, hid)
        if sample is None:
            continue
        
        try:
            info = extract_info(model, sample['image'], sample['env_data'], device)
            if info['alpha'] is not None:
                alphas.append(info['alpha'])
            all_importance.append(info['env_importance'])
        except Exception as e:
            continue
        
        # æ¸…ç†æ¢¯åº¦
        model.zero_grad()
    
    print(f"\n  æˆåŠŸåˆ†æ: {len(all_importance)} ä¸ªæ ·æœ¬")
    
    if len(all_importance) == 0:
        return None
    
    # è®¡ç®—ç»Ÿè®¡
    all_importance = np.array(all_importance)
    mean_importance = all_importance.mean(axis=0)
    std_importance = all_importance.std(axis=0)
    
    # å½’ä¸€åŒ–
    mean_importance_norm = mean_importance / (mean_importance.sum() + 1e-8)
    
    # Top 5
    top5_idx = np.argsort(mean_importance_norm)[::-1][:5].tolist()
    
    env_names = BIOCLIM_NAMES[:env_dim] if env_dim <= 19 else BIOCLIM_NAMES + PED_NAMES[:env_dim-19]
    
    # Alphaç»Ÿè®¡
    alpha_stats = {}
    if len(alphas) > 0:
        alphas = np.array(alphas)
        alpha_stats = {
            'mean': float(alphas.mean()),
            'std': float(alphas.std()),
            'min': float(alphas.min()),
            'max': float(alphas.max()),
            'median': float(np.median(alphas))
        }
        print(f"\n  Alphaç»Ÿè®¡:")
        print(f"    Mean: {alphas.mean():.4f} Â± {alphas.std():.4f}")
        print(f"    Range: [{alphas.min():.4f}, {alphas.max():.4f}]")
        print(f"    Median: {np.median(alphas):.4f}")
    
    print(f"\n  Top 5 ç¯å¢ƒå˜é‡:")
    for i, idx in enumerate(top5_idx):
        print(f"    {i+1}. [{idx:2d}] {env_names[idx]}: {mean_importance_norm[idx]:.4f}")
    
    return {
        'domain': name,
        'num_samples': len(all_importance),
        'total_samples': total_samples,
        'env_dim': env_dim,
        'env_names': env_names,
        'alpha_stats': alpha_stats,
        'env_importance': {
            'mean_importance': mean_importance_norm.tolist(),
            'std_importance': std_importance.tolist(),
            'top_5_indices': top5_idx,
            'top_5_importance': [float(mean_importance_norm[i]) for i in top5_idx],
            'top_5_names': [env_names[i] for i in top5_idx]
        }
    }


def main():
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"Device: {device}")
    
    # åŸŸé…ç½® - ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„
    configs = {
        'USA_Summer': {
            'data_dir': '/sunyuxuan/satbird/USA_summer',
            'checkpoint': '/sunyuxuan/satbird/runs/dinov2_v10_nir_enhanced_summer_seed42_20251201-153435/checkpoints/best-56-0.0522.ckpt'
        },
        'USA_Winter': {
            'data_dir': '/sunyuxuan/satbird/USA_winter',
            'checkpoint': '/sunyuxuan/satbird/runs/best winter/checkpoints/best-80-0.0479.ckpt'
        },
        'Kenya_Transfer': {
            'data_dir': '/sunyuxuan/satbird/kenya',
            'checkpoint': '/sunyuxuan/satbird/runs/transfer_usa_to_kenya_linear_seed42_20251202-023844/checkpoints/best-73-0.0694.ckpt'
        }
    }
    
    results = {}
    
    for name, cfg in configs.items():
        try:
            result = analyze_domain(
                name=name,
                data_dir=cfg['data_dir'],
                ckpt_path=cfg['checkpoint'],
                max_samples=2000,
                device=device
            )
            if result:
                results[name] = result
        except Exception as e:
            print(f"åŸŸ {name} åˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    # ä¿å­˜ç»“æœ
    out_dir = '/sunyuxuan/satbird/outputs/interpretability_v2'
    os.makedirs(out_dir, exist_ok=True)
    
    for name, result in results.items():
        with open(os.path.join(out_dir, f'{name}_analysis.json'), 'w') as f:
            json.dump(result, f, indent=2)
    
    # æ±‡æ€»
    print("\n" + "="*70)
    print("ğŸ“Š åˆ†ææ±‡æ€»")
    print("="*70)
    
    for name, result in results.items():
        print(f"\n{name}:")
        print(f"  æ ·æœ¬: {result['num_samples']}/{result['total_samples']} ({result['num_samples']/result['total_samples']*100:.1f}%)")
        if result['alpha_stats']:
            print(f"  Alpha: {result['alpha_stats']['mean']:.4f} Â± {result['alpha_stats']['std']:.4f}")
        print(f"  Top 3 å˜é‡: {', '.join(result['env_importance']['top_5_names'][:3])}")
    
    print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {out_dir}")


if __name__ == '__main__':
    main()
